{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1. CTC Implementation using Numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score 97.032\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import collections\n",
    "\n",
    "NEG_INF = -float(\"inf\")\n",
    "\n",
    "def make_new_beam():\n",
    "    fn = lambda : (NEG_INF, NEG_INF)\n",
    "    return collections.defaultdict(fn)\n",
    "\n",
    "def logsumexp(*args):\n",
    "    if all(a == NEG_INF for a in args):\n",
    "        return NEG_INF\n",
    "    a_max = max(args)\n",
    "    lsp = math.log(sum(math.exp(a - a_max)\n",
    "                      for a in args))\n",
    "    return a_max + lsp\n",
    "\n",
    "def decode(probability, beam_size=100, blank=0):\n",
    "  \"\"\"\n",
    "  Calculates inference for the given output probabilities.\n",
    "  Arguments:\n",
    "  probability: The output probabilities (e.g. post-softmax) for each\n",
    "  time step. Should be an array of shape (time x output dim).\n",
    "  beam_size (int): Size of the beam to use during inference.\n",
    "  blank (int): Index of the CTC blank label.\n",
    "  Returns the output label sequence and the corresponding negative\n",
    "  log-likelihood estimated by the decoder.\n",
    "  \"\"\"\n",
    "  T, S = probability.shape\n",
    "  probability = np.log(probability)\n",
    "\n",
    "  # Elements in the beam are (prefix, (p_blank, p_no_blank))\n",
    "  # Initialize the beam with the empty sequence, a probability of\n",
    "  # 1 for ending in blank and zero for ending in non-blank\n",
    "  beam = [(tuple(), (0.0, NEG_INF))]\n",
    "\n",
    "  for t in range(T): # Over time\n",
    "\n",
    "    #storing the next step candidates.\n",
    "    next_beam = make_new_beam()\n",
    "\n",
    "    for s in range(S): # Over vocab\n",
    "      p = probability[t, s]\n",
    "\n",
    "      # The variables p_b and p_nb are respectively the\n",
    "      # probabilities for the prefix given that it ends in a\n",
    "      # blank and does not end in a blank at this time step.\n",
    "      for prefix, (p_b, p_nb) in beam: # Loop over beam\n",
    "\n",
    "        # If we propose a blank the prefix doesn't change.\n",
    "        # Only the probability of ending in blank gets updated.\n",
    "        if s == blank:\n",
    "          n_p_b, n_p_nb = next_beam[prefix]\n",
    "          n_p_b = logsumexp(n_p_b, p_b + p, p_nb + p)\n",
    "          next_beam[prefix] = (n_p_b, n_p_nb)\n",
    "          continue\n",
    "\n",
    "        # Extend the prefix by the new character s and add it to\n",
    "        # the beam. Only the probability of not ending in blank\n",
    "        # gets updated.\n",
    "        end_t = prefix[-1] if prefix else None\n",
    "        n_prefix = prefix + (s,)\n",
    "        n_p_b, n_p_nb = next_beam[n_prefix]\n",
    "        if s != end_t:\n",
    "          n_p_nb = logsumexp(n_p_nb, p_b + p, p_nb + p)\n",
    "        else:\n",
    "          # We don't include the previous probability of not ending\n",
    "          # in blank (p_nb) if s is repeated at the end. The CTC\n",
    "          # algorithm merges characters not separated by a blank.\n",
    "          n_p_nb = logsumexp(n_p_nb, p_b + p)\n",
    "          \n",
    "        # *NB* this would be a good place to include an LM score.\n",
    "        next_beam[n_prefix] = (n_p_b, n_p_nb)\n",
    "\n",
    "        # If s is repeated at the end we also update the unchanged\n",
    "        # prefix. This is the merging case.\n",
    "        if s == end_t:\n",
    "            n_p_b, n_p_nb = next_beam[prefix]\n",
    "            n_p_nb = logsumexp(n_p_nb, p_nb + p)\n",
    "            next_beam[prefix] = (n_p_b, n_p_nb)\n",
    "\n",
    "    # Sort and trim the beam before moving on to the\n",
    "    # next time-step.\n",
    "    beam = sorted(next_beam.items(),\n",
    "            key=lambda x : logsumexp(*x[1]),\n",
    "            reverse=True)\n",
    "    beam = beam[:beam_size]\n",
    "\n",
    "  best = beam[0]\n",
    "  return best[0], -logsumexp(*best[1])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    np.random.seed(3)\n",
    "\n",
    "    time = 50\n",
    "    output_dim = 20\n",
    "\n",
    "    probability = np.random.rand(time, output_dim)\n",
    "    probability = probability / np.sum(probability, axis=1, keepdims=True)\n",
    "\n",
    "    labels, score = decode(probability)\n",
    "    print(\"Score {:.3f}\".format(score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
